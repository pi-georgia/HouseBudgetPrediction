sqd
dd <- data.table(dose=d_data$dose,len=d_data$len)
dd[,len_gain:=c(NA,diff(len)),by=dose] ; dd<-na.omit(dd)
dd
dd_dose <- group_by(dd, dose) %>% summarize(gain= sum(len_gain), step_gain = mean(len_gain))
dd_dose
d05 <- dd$len_gain[1:19] ; d1 <- dd$len_gain[20:38]; d2 <- dd$len_gain[39:57]
t_eval_1 <- t.test(d05,d1, paired=FALSE)
t_eval_1$statistic
t_eval_2 <- t.test(d1,d2, paired=FALSE)
t_eval_2$statistic
t_eval_2
t_eval_2 <- t.test(d1,d2, paired=FALSE, var.equal=FALSE)
t_eval_2$statistic
t_eval_2 <- t.test(d2, d1,paired=FALSE, var.equal=FALSE)
t_eval_2$statistic
t_eval_2 <- t.test(d2,d05, paired=FALSE, var.equal=FALSE)
t_eval_2$statistic
t_eval_3 <- t.test(d2,d05, paired=FALSE, var.equal=FALSE)
t_eval_3$statistic
t_eval_3
dd_dose
dd_dose <- group_by(dd, dose, supp) %>% summarize(gain= sum(len_gain), step_gain = mean(len_gain))
dd
dd <- data.table(dose=d_data$dose,len=d_data$len, supp=d_data$supp )
dd[,len_gain:=c(NA,diff(len)),by=dose] ; dd<-na.omit(dd)
dd
dd_dose <- group_by(dd, dose, supp) %>% summarize(gain= sum(len_gain), step_gain = mean(len_gain))
dd_dose
dd05<- dd_dose$gain[1:2]
dd05
dd1<- dd_dose$gain[3:4]
dd2<- dd_dose$gain[3:4]
dd2<- dd_dose$gain[5:6]
t_eval_1 <- t.test(dd1,dd05, paired=FALSE)
t_eval_1
t_eval_2 <- t.test(dd2,dd1, paired=FALSE)
t_Eval_2
t_eval_2
qt(0.975, 2)
t_eval_3 <- t.test(dd2,dd0.5, paired=FALSE)
t_eval_3 <- t.test(dd2,dd05, paired=FALSE)
t_eval_3
t_eval_3 <- t.test(d2,d05, paired=FALSE, var.equal=FALSE)
t_eval_3$statistic
t_eval_3
head(dd)
power.t.test(power=0.8, delta=1,sd=1)$n
power.t.test(power=0.8, delta=1,sd=0.5)$n
sd(dd$len_gain)
power.t.test(power=0.9, delta=1,sd=0.5)$n
power.t.test(power=0.9, delta=1,sd=0.8)$n
length(dd)
length(d2)
power.t.test(power=0.95, delta=1,sd=0.8)$n
power.t.test(power=0.95, delta=0.1,sd=0.8)$n
sd(d2)
sd(d1)
sd(d05)
power.t.test(delta=0.1, sd=0.5, n=19)
power.t.test(delta=0.1, sd=0.5, n=19)$power
power.t.test(delta=0.1, sd=0.5, n=38)$power
s_sd<- sd(dd$len_gain)
s_sd
t_eval_3
t_eval_3$mean.y
t_eval_3$meany
str(t.test)
str(t_eval_3)
s_delta = t_eval_3$estimate[1] - t_eval_3$estimate[2]
s_delta
power.t.test(delta=s_delta, sd=s_sd, n=38)$power
power.t.test(n=38, sd=s_sd, power= 0.9)$delta
s_delta2 = t_eval_2$estimate[1] - t_eval_2$estimate[2]
s_delta2
t_eval_2$estimate[1]
t_eval_2$estimate[2]
t_eval_1 <- t.test(d1,d05, paired=FALSE)
t_eval_1$statistic
sd(d1, d05)
sd(d1)
sd(d05)
dr[1:length(d1)]<- d1
dr<-0
dr[1:length(d1)]<- d1
dr[length(d1)+1:length(d05)]<- d05
dr[1:length(d1)]<- d1
dr[length(d1)+1:length(d1)+length(d05)]<- d05
dr
sd(dr)
power(sd=sd(dr), n=38, delta=0.85)
power.t.test(sd=sd(dr), n=38, delta=0.85, power=0.9)
power.t.test(sd=0.85, n=38, delta=0.85, power=0.9)
power.t.test(power=0.9, sd=0.85, n=38, delta=0.85, )
power.t.test(power=0.9, sd=0.85, n=38, delta=0.85)
power.t.test(power=0.9,delta=0.85, sd=0.85, n=38 )
power.t.test(delta=0.85, sd=0.85, n=38 )
power.t.test(delta=0.5, sd=0.85, n=38 )
delta1 = t_eval_1$estimate[1]- t_eval_1$estimate[1]
delta1
t_eval_1$estimate[1]
t_eval_1$estimate[2]
delta1 = t_eval_1$estimate[1]- t_eval_1$estimate[2]
delta1
power.t.test(n=(length(d1)+ length(d05)), delta=delta1, sd=sd(d1))
power.t.test(n=(length(d1)+ length(d05)), delta=delta1, sd=sd(d05))
delta1
power.t.test(n=(length(d1)+ length(d05)/2), delta=delta1, sd=sd(d1))
power.t.test(n=(length(d1)+ length(d05)/2), delta=delta1, sd=sd(d05))
sd1 <- sd(d1-d05)
sd1
mean(d1-d05)
power.t.test(n=(length(d1)+ length(d05)), delta=delta1, sd=sd1)$power
n1 <- power.t.test(power=0.9, delta=delta1, sd=sd1)$n
n1
round(n1,0)
delta2 = t_eval_2$estimate[1]- t_eval_1$estimate[2]
sd2 <- sd(d2-d1)
power2 <- power.t.test(n=(length(d2)+ length(d1)), delta=delta2, sd=sd2)$power
power2
delta2 = t_eval_2$estimate[1]- t_eval_1$estimate[2]
sd2 <- sd(d2-d1)
power2 <- power.t.test(n=(length(d2)+ length(d1))/2, delta=delta2, sd=sd2)$power
power2
length(d2)+ length(d1))/2
(length(d2)+ length(d1))/2
delta2
t_eval_2 <- t.test(d2, d1,paired=FALSE, var.equal=FALSE)
t_eval_2$statistic
delta2 = t_eval_2$estimate[1]- t_eval_1$estimate[2]
sd2 <- sd(d2-d1)
delta2
sd2
power2 <- power.t.test(n=(length(d2)+ length(d1)), delta=delta2, sd=sd2)$power
power2
n2 <- power.t.test(power=0.9, delta=delta2, sd=sd2)$n
round(n2,0)
t_eval_3 <- t.test(d2,d05, paired=FALSE, var.equal=FALSE)
t_eval_3$statistic
dd_dose
t_eval_22 <- t.test(dd2,dd1, paired=FALSE)
t_eval_22
del2<- t_eval_22$estimate[1] - t_eval_22$estimate[2]
del2
s22 <- sd(dd2 -dd1)
s22
power.t.test(delta=del2, sd=s22, n=2)$power
delta2 = t_eval_2$estimate[1]- t_eval_3$estimate[2]
sd2 <- sd(d2-d1)
delta2
delta2 = t_eval_2$estimate[1]- t_eval_2$estimate[2]
sd2 <- sd(d2-d1)
power2 <- power.t.test(n=(length(d2)+ length(d1)), delta=delta2, sd=sd2)$power
power2
delta3 = t_eval_3$estimate[1]- t_eval_3$estimate[2]
sd3 <- sd(d2-d05)
power3 <- power.t.test(n=(length(d2)+ length(d05))/2, delta=delta3, sd=sd3)$power
power3
n3 <- power.t.test(power=0.9, delta=delta3, sd=sd3)$n
round(n3,0)
x_OJ <- df$len_gain[1:27] ; y_VC <- df$len_gain[28:54]
#running a t test
t_eval <- t.test(x_OJ,y_VC, paired=FALSE)
t_eval$statistic
# How powerful is my test ?
delta0 = t_eval_$estimate[1]- t_eval_$estimate[2]
sd0 <- sd(x_OJ-y_VC)
power0 <- power.t.test(n=(length(x_OJ )+ length(dy_VC))/2, delta=delta0, sd=sd0)$power
power0
x_OJ <- df$len_gain[1:27] ; y_VC <- df$len_gain[28:54]
#running a t test
t_eval <- t.test(x_OJ,y_VC, paired=FALSE)
t_eval$statistic
# How powerful is my test ?
delta0 = t_eval_$estimate[1]- t_eval_$estimate[2]
sd0 <- sd(x_OJ-y_VC)
power0 <- power.t.test(n=(length(x_OJ )+ length(y_VC))/2, delta=delta0, sd=sd0)$power
power0
t_eval_$estimate[1]
t_Eval
t_eval
delta0 = t_eval$estimate[1]- t_eval$estimate[2]
sd0 <- sd(x_OJ-y_VC)
power0 <- power.t.test(n=(length(x_OJ )+ length(y_VC))/2, delta=delta0, sd=sd0)$power
power0
n0 <- power.t.test(power=0.9, delta=delta0, sd=sd0)$n
round(n0,0)
grid.arrange(sq, bq, dq, nrow=3, col= 2)
# scatterplot/  primary visualization of my dataset
sq<- qplot(data=tdata, y=len,x=dose, color= supp, xlab = "dose category", ylab="teeth length",main="Teeth lengths per dose and supplement types", labels="supplement type")
# boxplot/ informative visualization of my variables statistics
bq<- qplot(data=tdata, y=len, x= supp,fill=supp, facets=. ~ dose,geom="boxplot", xlab = "dose category",ylab="teeth length", main="Length boxplots per dose and supplement types", labels="supplement type")
# plot variable distributions/ densities, better understand my variable characteristics
dq<- qplot(data=tdata, x=len, color= supp,geom="density",  facets=. ~ dose, xlab = "length | dose category", main="Length density per dose and supplement types", labels="supplement type")
#arrange objects and then plot
grid.arrange(sq, bq, dq, nrow=3, ncol= 2)
powertable = c(round(100*power1, 2), round(100*power2, 2), round(100*power3, 2))
power1 <- power.t.test(n=(length(d1)+ length(d05))/2, delta=delta1, sd=sd1)$power
power2 <- power.t.test(n=(length(d2)+ length(d1))/2, delta=delta2, sd=sd2)$power
power3 <- power.t.test(n=(length(d2)+ length(d05))/2, delta=delta3, sd=sd3)$power
powertable = c(round(100*power1, 2), round(100*power2, 2), round(100*power3, 2))
powertable
grid.arrange()
grid.arrange
?grid.arrange
devtools::install_github("rstudio/rmarkdown")
rmarkdown::render('in.md',
output_format=pdf_document(latex_engine='xelatex')
)
install.packages("framed")
?mutate
color()
color
colour
library(ggplot2)
colour
color
col
WE <-c("Saturday", "Sunday")
WE
"Sunday" in WE
in("Sunday",WE)
?in
?match
"Sunday" %in% WE
"Saturday" %in% WE
"Tuesday" %in% WE
?geom_point
?geom_line
x.norm<-rnorm(n=100,m=0,sd=1)
str(x.norm)
lambda <- 0.2
#calculate the mean, the standard deviation and the variance of each exponential distribution
mean<- 1/lambda ; std<- 1/lambda ; var= std^2 ; n<-40
#running 1000 simulations of exponential distributions, all with lambda=0.2, n=40
#for each one, I am calculating each mean (mean(rexp(n, lambda)) and saving it to a table "mns"
ens<- NULL; sens<- NULL; mns<-NULL ; vns<- NULL
for (i in 1 : 1000)
{
#run simulation of exponential & add to the estimates table
dist<- rexp(n, lambda) ; ens<-c(ens, dist)
#mean  & varianceof n samples simulation calculated and stored in the relevant table, aka mns and vns
mns <- c(mns, mean(dist)); vns <- c(vns, sd(dist)^2 ) }
# normalized distribution of means
d <- (ens - mns)*sqrt(n)/std
#plot the distribution of sample mean
hist(mns, breaks= 40, main="Samples Mean Distribution & Theoretical Mean", xlab="samples mean", col= "azure", border="gray60")
#plot the theoretical mean, in red
abline(v=mean, col= "red", lty=3, lwd= 3)
#distribution of sample variance is plotted in a histogram
hist(vns, breaks= 40,main="Samples Variance Distribution & Theoretical Variance", xlab="samples variance", col= "thistle", border="gray60")
#the theoretical variance is added with a blue line
abline(v=var, col= "blue", lty=3, lwd= 3)
hist(d, main="Distribution of means, normalized", col="wheat", border="wheat", breaks=100)
abline(v=mean(d), col="red", lwd= 3) ; abline(v=sd(d), col="violet", lty=2, lwd= 1)
abline(v=-sd(d), col="violet", lty=2, lwd= 1)
x.norm<-rnorm(n=100,m=0,sd=1)
abline(x=x.norm, col="violet", lty=2, lwd= 1)
abline(a=x.norm, col="violet", lty=2, lwd= 1)
?abline
abline(x.norm, col="violet", lty=2, lwd= 1)
plot(density(d),main="Density estimate of data")
plot(density(x.norm),main="Density estimate of data")
plot(density(d),main="Density estimate of data")
#distribution of sample variance is plotted in a histogram
hist(vns, breaks= 40,main="Samples Variance Distribution & Theoretical Variance", xlab="samples variance", col= "thistle", border="gray60")
#the theoretical variance is added with a blue line
abline(v=var, col= "blue", lty=3, lwd= 3)
hist(d, main="Distribution of means, normalized", col="wheat", border="wheat", breaks=100)
abline(v=mean(d), col="red", lwd= 3) ; abline(v=sd(d), col="violet", lty=2, lwd= 1)
abline(v=-sd(d), col="violet", lty=2, lwd= 1)
lines(x.norm)
?lines
lines(y=x.norm)
lines(x=index(x.norm), y=x.norm)
?index
??
index
h<- hist(x.norm, breaks=100)
xi<- c(h$breaks)
xi
yi<- h$density
length(xi)
length(yi)
yi<- c(0, h$density)
length(yi)
lines(xi, yi)
lines (density(x.norm), add = TRUE, col="red")
lines (density(x.norm), col="red")
lines (density(x.norm), col="red")
dh<- hist(d, main="Distribution of means, normalized", col="wheat", border="wheat", breaks=100)
lines (density(dh), col="red")
lines (density(h), col="red")
lines (density(d), col="red")
lines (density(d), col="red", add=TRUE)
?lines
dh<- hist(d, main="Distribution of means, normalized", col="wheat", border="wheat", breaks=100)
dh<- hist(d, main="Distribution of means, normalized", col="wheat", border="wheat", breaks=100, prob=TRUE)
curve(x.norm, add=TRUE)
xnorm<-rnorm(n=100,m=0,sd=1)
curve(xnorm, add=TRUE)
curve(rnorm(n=100,m=0,sd=1), add=TRUE)
?curve
curve(dnorm(xnorm,m=0,sd=1), add=TRUE)
lines (density(d), col="red", add=TRUE)
lines (density(xnorm), col="blue", add=TRUE)
lines (density(xnorm), col="blue")
lines (density(xnorm), col="blue")
?rexp
n_rdm<- sample(30:1000, 500)
n_rdm
sample_var<- sd(vns)^2
samplevar
sample_var
sample_var<- sd(mns)^2
sample_var
sample_var<- mean(vns)
sample_var
install.packages("caret")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
ggplot(data=ww,aes(x=interval,y=avg_steps)) + facet_wrap(~w_class, scales="free",  nrow = 2) +labs( title="Activity Patterns", y="Frequency in dataset", x="# average steps")
daily <- group_by(dataset, date)
#calculate sums of steps by date
dailysum<- summarize(daily,total_steps= sum(steps, na.rm=TRUE))
#make a histogram : I will choose a binwidth that is at a scale relevant to the daily sum of steps, by choice 1000
library(ggplot2)
ggplot(dailysum, aes(x=total_steps, fill='violet')) + geom_histogram(binwidth =1000) +labs( title="Total Daily Steps Histogram", y="Frequency in dataset", x="# Total Daily Steps")
mn<- mean(dailysum$total_steps) ; mn<- round(mn, 2)
md<- median(dailysum$total_steps)
dataset <- read.csv("activity.csv")
setwd("~/Documents/Work/1. Data Science/Reproducible Research/RepData_PeerAssessment1")
dataset <- read.csv("activity.csv")
daily <- group_by(dataset, date)
#calculate sums of steps by date
dailysum<- summarize(daily,total_steps= sum(steps, na.rm=TRUE))
#make a histogram : I will choose a binwidth that is at a scale relevant to the daily sum of steps, by choice 1000
library(ggplot2)
ggplot(dailysum, aes(x=total_steps, fill='violet')) + geom_histogram(binwidth =1000) +labs( title="Total Daily Steps Histogram", y="Frequency in dataset", x="# Total Daily Steps")
mn<- mean(dailysum$total_steps) ; mn<- round(mn, 2)
md<- median(dailysum$total_steps)
library(dplyr)
daily <- group_by(dataset, date)
#calculate sums of steps by date
dailysum<- summarize(daily,total_steps= sum(steps, na.rm=TRUE))
#make a histogram : I will choose a binwidth that is at a scale relevant to the daily sum of steps, by choice 1000
library(ggplot2)
ggplot(dailysum, aes(x=total_steps, fill='violet')) + geom_histogram(binwidth =1000) +labs( title="Total Daily Steps Histogram", y="Frequency in dataset", x="# Total Daily Steps")
mn<- mean(dailysum$total_steps) ; mn<- round(mn, 2)
md<- median(dailysum$total_steps)
interval <- group_by(dataset,as.factor( interval)) %>% summarize(daily_avg_steps=mean(steps, na.rm=TRUE))
names(interval)[1]<-"interval_class"
plot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet", xlab="5 minute interval" , type="l")
plot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet", xlab="5 minute interval" , type="l")
?plot
plot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet", xlab="5 minute interval" , type="b")
plot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", colour= "violet", xlab="5 minute interval" , type="b")
plot(interval$interval_class, interval$daily_avg_steps, colour= "violet",  type="b",main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps, colour= "violet",  type="b",main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", xlab="5 minute interval" )
?qplot
qplot(interval$interval_class, interval$daily_avg_steps, colour= "violet",  geom="dotplot",main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="path" xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="path", xlab="5 minute interval" )
??geom
geom
geom()
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="line", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="line", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="line", xlab="5 minute interval" )
qplot(interval$interval_class, interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="jitter", xlab="5 minute interval" )
interval[1:3,]
qplot(as.integer(interval$interval_class), interval$daily_avg_steps,main="Activity Pattern, across a day (avg)", ylab="# of Steps, on average", col= "violet",geom="line", xlab="5 minute interval" )
head(ww)
nnn<- dce20612bf6f87f205b4fb03f537d61f131d733f
nnn<- "dce20612bf6f87f205b4fb03f537d61f131d733f"
counta(nnn)
count(nnn)
?count
?str
?nchar
nchar(nnn)
nchar("15e3328d53532ed61b869d1986963f3fcb2dc3da")
nchar(nnn)
setwd("~/Documents/Work/1. Data Science/Developing Data Products/Data Product 1")
install.packages("shiny")
library(shiny)
runapp()
runApp()
?radioButtons
runApp()
submitButton
?submitButton
runApp()
runApp()
?subset
runApp()
runApp()
data<-read.csv('housedata.csv')
head(data)
str(data)
area="City Center"
Rooms=1
Type="flat"
Surface=c(40,200)
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type)&(Surface %in% surface),select=c(Price, Psqm))
surface=c(40,200)
type="flat"
rooms=1
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type)&(Surface %in% surface),select=c(Price, Psqm))
str(pred_data)
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type)),select=c(Price, Psqm))
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type),select=c(Price, Psqm))
str(pred_data)
area
str(data)
rooms=2
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type),select=c(Price, Psqm))
str(pred_data)
data$Area=="City Center"
data$Rooms[data$Area=="City Center"]
data$Type[data$Area=="City Center"]
type
type="Flat"
pred_data<- subset(data,(Area==area) &(Rooms %in% rooms) &(Type %in% type),select=c(Price, Psqm))
str(pred_data)
price_min<- mean(pred_data$price) - sd(pred_data$price)price_max<- mean(pred_data$price) +  sd(pred_data$price)prediction <-c(price_min, price_max)
price_min<- mean(pred_data$Price) - sd(pred_data$Price)price_max<- mean(pred_data$Price) +  sd(pred_data$Price)prediction <-c(price_min, price_max)
price_min<- mean(pred_data$Price) - sd(pred_data$Price)
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)
prediction <-c(price_min, price_max)
prediction
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2prediction <-c(price_min, price_max)
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2
prediction <-c(price_min, price_max)
prediction
runApp()
runApp()
setwd("~/Documents/Work/1. Data Science/Developing Data Products/Data Product 1/HouseBudgetPrediction")
runApp()
houseBudget("City Center", 200, 2, "Flat")
houseBudget <- function(area, surface, rooms, type)
{
data<-read.csv('housedata.csv')
prediction<-c(150,200) ;  price_min<-0 ;  price_max<-0
pred_data<- subset(data,(Area==area) &(Type %in% type)&(Surface %in% surface),select=c(Price, Psqm))
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2
prediction <-c(price_min, price_max)
prediction
}
houseBudget("City Center", 200, 2, "Flat")
houseBudget("City Center", "200", 2, "Flat")
houseBudget("City Center", "200", "2", "Flat")v
houseBudget("City Center", "200", "2", "Flat")
str(data)
houseBudget <- function(area="City Center", surface=50, rooms=2, type="Flat")
{
data<-read.csv('housedata.csv')
prediction<-c(150,200) ;  price_min<-0 ;  price_max<-0
pred_data<- subset(data,(Area==area) &(Type %in% type)&(Surface >min(surface)) & (Surface < max(surface)),select=c(Price, Psqm))
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2
prediction <-c(price_min, price_max)
prediction
}
houseBudget()
area="City Center"
surface=50
rooms=2
type="Flat"
prediction<-c(150,200) ;  price_min<-0 ;  price_max<-0
pred_data<- subset(data,(Area==area) &(Type %in% type)&(Surface >min(surface)) & (Surface < max(surface)),select=c(Price, Psqm))
str(pred_data)
data[(data$Area==area)&(data$Type %in% type)]
data[(data$Area==area)&(data$Type %in% type),]
data[(data$Area==area)&(data$Type %in% type)&(data$Surface > min(surface)) & (data$Surface < max(surface)),]
h<-data$Surface > min(surface)
str(h)
y<-data$Surface < max(surface)
str(y)
y=="TRUE"
which(y)
which(h)
which(y) & which(h)
which(y&h)
max(surface)
y<-data$Surface <= max(surface)
h<-data$Surface >= min(surface)
which(y&h)
pred_data<- subset(data,(Area==area) &(Type %in% type)&(Surface >=min(surface)) & (Surface <= max(surface)),select=c(Price, Psqm))
str(pred_data)
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2
prediction <-c(price_min, price_max)
prediction
houseBudget <- function(area="City Center", surface=50, rooms=2, type="Flat")
{
data<-read.csv('housedata.csv')
prediction<-c(150,200) ;  price_min<-0 ;  price_max<-0
pred_data<- subset(data,(Area==area) &(Type %in% type)&(Surface >=min(surface)) & (Surface <= max(surface)),select=c(Price, Psqm))
price_min<- mean(pred_data$Price) - sd(pred_data$Price)/2
price_max<- mean(pred_data$Price) +  sd(pred_data$Price)/2
prediction <-c(round(price_min), round(price_max))
prediction
}
houseBudget
houseBudget()
houseBudget(area="North Suburbs")
runApp()
runApp()
runApp()
